import os
from collections import OrderedDict
import numpy as np
import pandas as pd
from PIL import Image
import cv2
import matplotlib.pyplot as plt
from tqdm import tqdm
from mpi4py import MPI
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import models
from torchvision.utils import make_grid
from albumentations.pytorch import ToTensorV2
import albumentations as A
from torchmetrics import JaccardIndex
from albumentations import Compose, Normalize

config = {'device': torch.device("cuda:0" if torch.cuda.is_available() else "cpu"), 'batch_size': 2, 'learning_rate': 0.001,}
device=config['device']
batch_size=config['batch_size']
lr=config['learning_rate']

color_codes = OrderedDict({
                'Animal': [64, 128, 64],
                'Archway': [192, 0, 128],
                'Bicyclist': [0, 128, 192],
                'Bridge': [0, 128, 64],
                'Building': [128, 0, 0],
                'Car': [64, 0, 128],
                'CartLuggagePram': [64, 0, 192],
                'Child': [192, 128, 64], 
                'Column_Pole': [192, 192, 128],
                'Fence': [64, 64, 128],
                'LaneMkgsDriv': [128, 0, 192],
                'LaneMkgsNonDriv': [192, 0, 64],
                'Misc_Text': [128, 128, 64],
                'MotorcycleScooter': [192, 0, 192],
                'OtherMoving': [128, 64, 64],
                'ParkingBlock': [64, 192, 128],
                'Pedestrian': [64, 64, 0],
                'Road': [128, 64, 128],
                'RoadShoulder': [128, 128, 192],
                'Sidewalk': [0, 0, 192],
                'SignSymbol': [192, 128, 128],
                'Sky': [128, 128, 128],
                'SUVPickupTruck': [64, 128, 192],
                'TrafficCone': [0, 0, 64],
                'TrafficLight': [0, 64, 64],
                'Train': [192, 64, 128],
                'Tree': [128, 128, 0],
                'Truck_Bus': [192, 128, 192],
                'Tunnel': [64, 0, 64],
                'VegetationMisc': [192, 192, 0],
                'Void': [0, 0, 0],
                'Wall': [64, 192, 0]
})

class CamSeqDataset(Dataset):
    def __init__(self, img_dir, color_codes=color_codes, state=True,transforms=None):
        super().__init__()
        self.images = sorted([os.path.join(img_dir, x) for x in os.listdir(img_dir) if not x.split('.')[0].endswith('_L')])
        self.images = [x for x in self.images if not x.endswith('.txt')]
        self.masks = sorted([os.path.join(img_dir, x) for x in os.listdir(img_dir) if x.split('.')[0].endswith('_L')])
        self.color_codes = color_codes
        self.num_classes = len(self.color_codes)
        self.transforms = transforms
        
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        
        img = Image.open(self.images[idx])
        mask = Image.open(self.masks[idx])
        
        if img.mode != 'RGB':
            img = img.convert('RGB')
        if mask.mode != 'RGB':
            mask = mask.convert('RGB')
            
        img = np.asarray(img)
        mask = np.asarray(mask)
        mask_channels = np.zeros(
            (mask.shape[0], mask.shape[1]), dtype=np.int64)
        
        for i, cls in enumerate(self.color_codes.keys()):
            color = self.color_codes[cls]
            sub_mask = np.all(mask==color, axis=-1)*i
            mask_channels += sub_mask #*i
            
        mask_channels = mask_channels.astype(np.float32)
        img = img.astype(np.float32) #/255
        
        instance = {'image': torch.from_numpy(img.transpose(2,0,1)),
                    'mask': torch.from_numpy(mask_channels)}
        
        return instance

def make_lraspp(num_classes=32):
    model = models.segmentation.lraspp_mobilenet_v3_large(pretrained=False, num_classes=num_classes)
    return model

def train_model(model, train_loader, val_loader, criterion= nn.CrossEntropyLoss(), num_epochs=1, device=device):
    model.to(device)
    jaccard = JaccardIndex(task="multiclass", num_classes=32)
    batch_IoU = []
    optimizer = optim.Adam(model.parameters(), lr=lr)
    for epoch in range(1, num_epochs + 1):
        tr_loss = []
        val_loss = []
        model.train()
        if my_rank == 0:
            print('Epoch {}/{}'.format(epoch, num_epochs))
            it = 0
            for sample in tqdm(train_loader):
                comm.send(sample, dest=it % (p - 1) + 1)
                it += 1
        if my_rank != 0:
            for i in range(len(train_loader)):
                if i % (p - 1) + 1 == my_rank:
                    sample = comm.recv(source=0)
                    inputs = sample['image'].to(device)
                    masks = sample['mask'].to(device)
                    optimizer.zero_grad() #
                    outputs = model(inputs)
                    y_pred = outputs['out']
                    batch_IoU.append(jaccard(y_pred, masks))
                    loss = criterion(y_pred.float(), masks.long())
                    loss.backward() #
                    tr_loss.append(loss)
                    optimizer.step() #
        MPI.Comm.Barrier(MPI.COMM_WORLD)
        if my_rank != 0:
            print(f'Process: {my_rank}, train loss: {torch.mean(torch.Tensor(tr_loss))}, train IoU: {torch.mean(torch.Tensor(batch_IoU))}')
        batch_IoU = []
        model.eval()
        if my_rank == 0:
            it = 0
            for sample in tqdm(val_loader):
                comm.send(sample, dest=it % (p - 1) + 1)
                it += 1
        if my_rank != 0:
            for i in range(len(val_loader)):
                if i % (p - 1) + 1 == my_rank:
                    sample = comm.recv(source=0)
                    inputs = sample['image'].to(device)
                    masks = sample['mask'].to(device)
                    with torch.no_grad():
                        outputs = model(inputs)
                    y_pred = outputs['out']
                    batch_IoU.append(jaccard(y_pred, masks))
                    loss = criterion(y_pred.float(), masks.long())
                    val_loss.append(loss)
                    optimizer.step()
        MPI.Comm.Barrier(MPI.COMM_WORLD)
        if my_rank != 0:
            print(f'Process: {my_rank}, validation loss: {torch.mean(torch.Tensor(val_loss))}, train IoU: {torch.mean(torch.Tensor(batch_IoU))}')
    return model

def test_models(model, test_loader, criterion= nn.CrossEntropyLoss(), device=device):
    model.to(device)
    jaccard = JaccardIndex(task="multiclass", num_classes=32)
    batch_IoU = []
    test_loss = []
    model.eval()
    if my_rank != 0:
        for sample in tqdm(test_loader):
            inputs = sample['image'].to(device)
            masks = sample['mask'].to(device)
            with torch.no_grad():
                outputs = model(inputs)
            y_pred = outputs['out']
            comm.send(y_pred, dest=0, tag=0)
            batch_IoU.append(jaccard(y_pred, masks))
            loss = criterion(y_pred.float(), masks.long())
            test_loss.append(loss)
    if my_rank == 0:
        for sample in tqdm(test_loader):
            y_pred = 0
            for pr in range(1, p):
                if pr == 1:
                    y_pred = comm.recv(source=pr, tag=0)
                else:
                    y_pred += comm.recv(source=pr, tag=0)
            y_pred /= p - 1
            masks = sample['mask'].to(device)
            batch_IoU.append(jaccard(y_pred, masks))
            loss = criterion(y_pred.float(), masks.long())
            test_loss.append(loss)

    print(f'Process: {my_rank}, test loss: {torch.mean(torch.Tensor(test_loss))}, test IoU: {torch.mean(torch.Tensor(batch_IoU))}')

if __name__ == "__main__":
    comm = MPI.COMM_WORLD
    my_rank = comm.Get_rank()
    p = comm.Get_size()
        
    dataset = CamSeqDataset(img_dir='./', state=True)
    train_size = int(len(dataset)*0.5)
    train_set, val_test_set = random_split(dataset, [train_size, len(dataset) - train_size])

    val_size = int(len(val_test_set) * 0.5)

    test_set, val_set = random_split(val_test_set, [val_size, int(len(val_test_set) - val_size)])

    train_loader = DataLoader(train_set, batch_size=batch_size)
    val_loader = DataLoader(val_set, batch_size=batch_size)
    test_loader = DataLoader(test_set, batch_size=batch_size)

    model = make_lraspp()

    model = train_model(model=model, train_loader=train_loader, val_loader=val_loader, num_epochs=10)

    model = test_models(model=model, test_loader=test_loader)

    MPI.Finalize